{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e50f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper\n",
    "import feedparser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1677103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_news_from_feed(feed_url):\n",
    "    articles= []\n",
    "    feed = feedparser.parse(feed_url)\n",
    "    for entry in feed.entries:\n",
    "        # create a newspaper article object\n",
    "        article = newspaper.Article(entry.link)\n",
    "        # download and parse the article\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        # extract relevant information\n",
    "        articles.append({\n",
    "            'title': article.title,\n",
    "            'author': article.authors,\n",
    "            'publish_date': article.publish_date,\n",
    "            'content': article.text\n",
    "        })\n",
    "    return articles\n",
    "\n",
    "\n",
    "feed_url='https://www.theguardian.com/uk/rss'\n",
    "articles = scrape_news_from_feed(feed_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe0abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(articles)\n",
    "print(df)\n",
    "#print extracted articles\n",
    "#for article in articles:\n",
    "#    ('Title:', article['title'])\n",
    "#    ('Author:', article['author'])\n",
    "#    ('Publish Date:', article['publish_date'])\n",
    "#    ('Content:', article['content'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
